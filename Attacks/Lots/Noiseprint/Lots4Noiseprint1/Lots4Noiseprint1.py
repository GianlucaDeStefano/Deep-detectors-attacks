import logging
import os

import numpy as np
from matplotlib import pyplot as plt
from tqdm import tqdm

from Attacks.Lots.Noiseprint.Lots4NoiseprintBase import Lots4NoiseprintBase
from Attacks.utilities.visualization import visuallize_array_values
from Ulitities.Image.Picture import Picture

def normalize_noiseprint_no_margins(noiseprint):
    v_min = np.min(noiseprint)
    v_max = np.max(noiseprint)
    return ((noiseprint - v_min) / (v_max - v_min)).clip(0, 1)


class LotsNoiseprint1(Lots4NoiseprintBase):

    def __init__(self, objective_image: Picture, objective_mask: Picture, target_representation_image: Picture = None,
                 target_representation_mask: Picture = None, qf: int = None,
                 patch_size: tuple = (16, 16), padding_size=(32, 32, 32, 32),
                 steps=50, debug_root="./Data/Debug/", alpha=5, plot_interval=10,verbose=True):
        """
        Base class to implement various attacks
        :param objective_image: image to attack
        :param objective_mask: binary mask of the image to attack, 0 = authentic, 1 = forged
        :param image_path: path to the image's file
        :param mask_path: path to the image's mask's file
        :param qf: quality factor to use
        :param patch_size: size of the patch ot use to generate the target representation
        :param steps: total number of steps of the attack
        :param debug_root: root dolder in which save debug data generated by the attack
        """

        if not padding_size:
            padding_size = (0, 0, 0, 0)

        # Define the dimension of the padding to apply to the patch before od using noiseprint
        self.padding_size = padding_size

        # convert targt image to be float
        objective_image = objective_image.astype(np.float)

        super().__init__("LOTS4Noiseprint_1", objective_image, objective_mask, target_representation_image,
                         target_representation_mask,
                         qf, patch_size, steps,
                         debug_root, alpha, plot_interval,verbose)

    def _on_before_attack(self):
        super(LotsNoiseprint1, self)._on_before_attack()
        self.write_to_logs("Padding patches on each dimension by:{}".format(self.padding_size))

    def _generate_target_representation(self, image: Picture, mask: Picture):
        """
        Generate the target representation executing the following steps:

            1) Divide the image into patches
            2) Select only the authentic patches
            3) Foreach patch compute its noiseptint
            4) Average all the noiseprint maps

        :return: the target representation in the shape of a numpy array
        """

        authentic_patches = image.get_authentic_patches(mask, self.patch_size, self.padding_size,
                                                        force_shape=True,
                                                        zero_padding=True)

        complete_patch_size = (self.patch_size[0] + self.padding_size[1] + self.padding_size[3],
                               self.patch_size[1] + self.padding_size[0] + self.padding_size[2])

        # create target patch object
        target_patch = np.zeros(complete_patch_size)

        patches_map = np.zeros(image.shape)

        # generate authentic target representation
        self.write_to_logs("Generating target representation...", logging.INFO)
        for original_patch in tqdm(authentic_patches):
            assert (original_patch.shape == target_patch.shape)

            noiseprint_patch = np.squeeze(self._engine._model(original_patch[np.newaxis, :, :, np.newaxis]))

            target_patch += noiseprint_patch / len(authentic_patches)

            patches_map = original_patch.no_paddings().add_to_image(patches_map)

        self.write_to_logs("Target representation generated", logging.INFO)

        t_no_padding = authentic_patches[0].no_paddings(target_patch)

        # save a visualization of the target representation
        normalized_noiseprint = normalize_noiseprint_no_margins(t_no_padding)

        plt.imsave(fname=os.path.join(self.debug_folder, "image-target.png"), arr=normalized_noiseprint, cmap='gray',
                   format='png')

        visuallize_array_values(t_no_padding, os.path.join(self.debug_folder, "image-target-raw.png"))

        patches_map = Picture(patches_map)
        patches_map.save(os.path.join(self.debug_folder, "patches-map.png"))

        # save target representation t in a 8x8 grid for visualization purposes
        if t_no_padding.shape[0] % 8 == 0 and t_no_padding.shape[1] % 8 == 0:

            patch_8 = np.zeros((8, 8))
            n_patches8 = (t_no_padding.shape[0] // 8) * (t_no_padding.shape[1] // 8)
            for x in range(0, t_no_padding.shape[0], 8):
                for y in range(0, t_no_padding.shape[1], 8):
                    patch_8 += t_no_padding[x:x + 8, y:y + 8] / n_patches8

            visuallize_array_values(patch_8, os.path.join(self.debug_folder, "clean_target_patch.png"))

        return target_patch

    def _get_gradient_of_image(self, image: Picture, target: Picture):
        """
        Perform step of the attack executing the following steps:

            1) Divide the entire image into patches
            2) Compute the gradient of each patch with respect to the patch-tirget representation
            3) Recombine all the patch-gradients to obtain a image wide gradient
            4) Apply the image-gradient to the image
            5) Convert then the image to the range of values of integers [0,255] and convert it back to the range
               [0,1]
        :return:
        """

        # variable to store the cumulative loss across all patches
        cumulative_loss = 0

        # image wide gradient
        image_gradient = np.zeros((image.shape[0:2]))

        # divide the image into patches
        img_patches = image.divide_in_patches(self.patch_size, self.padding_size, zero_padding=True)

        # analyze the image patch by patch
        for patch in tqdm(img_patches):

            # check if we are on a border and therefore we have to "cut"tareget representation
            target_patch_representation = target

            # if we are on a border, cut away the "overflowing target representation"
            if target_patch_representation.shape != patch.shape:
                target_patch_representation = target_patch_representation[:patch.shape[0],
                                              :patch.shape[1]]

            # compute the gradient of the input w.r.t. the target representation
            patch_gradient, patch_loss = self._get_gradient_of_patch(patch, target_patch_representation)

            # check that the retrieved gradient has the correct shape
            assert (patch_gradient.shape == patch.shape)

            # add this patch's loss contribution
            cumulative_loss += patch_loss

            # remove padding from the gradient
            patch_gradient = patch.no_paddings(patch_gradient)

            # Add the contribution of this patch to the image wide gradient removing the padding
            image_gradient = patch.add_to_image(image_gradient, patch_gradient)

        return image_gradient, cumulative_loss
